{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'tensorflow==1.5.0'\n",
    "# !pip install 'edward==1.3.5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ShvVUXv8kDu7"
   },
   "source": [
    "# Configure env..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DXjxHH6et_yc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed:  1592223649\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import numpy.random as npr\n",
    "import os\n",
    "from datetime import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from scipy.stats import invgamma\n",
    "from edward.models import Normal, Gamma, Dirichlet, InverseGamma, \\\n",
    "    Poisson, PointMass, Empirical, ParamMixture, \\\n",
    "    MultivariateNormalDiag, Categorical, Laplace,\\\n",
    "    MultivariateNormalTriL, Bernoulli, TransformedDistribution, \\\n",
    "    Binomial\n",
    "from edward.util import Progbar\n",
    "from scipy import sparse, stats\n",
    "from scipy.special import expit, logit\n",
    "# from deconfounder_poissonMF import PoissonMF\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "plt.style.use('ggplot')\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.10f}\".format(x)})\n",
    "\n",
    "# set random seed so everyone gets the same number\n",
    "import random\n",
    "import time\n",
    "randseed = int(time.time())\n",
    "# random seed for reproducibility\n",
    "randseed = 1592223649\n",
    "print(\"random seed: \", randseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory\n",
    "DATA_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-cause simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPCA():\n",
    "\n",
    "\n",
    "    \"\"\"Poisson Matrix Factorization \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array\n",
    "        patient-causes matrix, count or binary\n",
    "    K : integer\n",
    "        number of latent class\n",
    "    M : integer\n",
    "        mini-batch size for stochastic optimization. M <= X.shape[1]\n",
    "    holdout_portion: float\n",
    "        number of holdout datapoints. Between 0 and 1\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, K, M, holdout_portion):\n",
    "        self.X = X\n",
    "        self.K = K\n",
    "        self.M = M\n",
    "        self.holdout_portion = holdout_portion\n",
    "    # for stochastic optimization\n",
    "    # subsample genes\n",
    "    def __next_batch(self, x_train):\n",
    "        idx_batch = np.random.choice(self.N, self.M)\n",
    "        return x_train[:, idx_batch], idx_batch\n",
    "    def __holdout(self):\n",
    "        # randomly holdout some entries of X\n",
    "        num_datapoints, data_dim = self.X.shape\n",
    "        n_holdout = int(self.holdout_portion * num_datapoints * data_dim)\n",
    "\n",
    "        holdout_row = np.random.randint(num_datapoints, size=n_holdout)\n",
    "        holdout_col = np.random.randint(data_dim, size=n_holdout)\n",
    "        holdout_mask = (sparse.coo_matrix((np.ones(n_holdout), \\\n",
    "                                    (holdout_row, holdout_col)), \\\n",
    "                                    shape = self.X.shape)).toarray()\n",
    "        holdout_mask = np.minimum(holdout_mask, np.ones(self.X.shape))\n",
    "        holdout_mask = np.float32(holdout_mask)\n",
    "\n",
    "\n",
    "        holdout_subjects = np.unique(holdout_row)\n",
    "\n",
    "        x_train = np.multiply(1-holdout_mask, self.X)\n",
    "        x_vad = np.multiply(holdout_mask, self.X)\n",
    "        return x_train, x_vad, holdout_row, holdout_col, holdout_mask\n",
    "    \n",
    "    def coef_(self):\n",
    "        return self.x_post_np\n",
    "\n",
    "    def run(self):\n",
    "        x_train, x_vad, holdout_row, holdout_col, holdout_mask = self.__holdout()\n",
    "        self.N = x_train.shape[1]  # number of data points\n",
    "        self.D = x_train.shape[0]  # data dimensionality\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        sess = tf.InteractiveSession()\n",
    "\n",
    "        # MODEL\n",
    "        idx_ph = tf.placeholder(tf.int32, self.M)\n",
    "        x_ph = tf.placeholder(tf.float32, [self.D, self.M])\n",
    "\n",
    "        w = Normal(loc=0.0, scale=1.0, sample_shape=[self.D, self.K])\n",
    "        z = Normal(loc=0.0, scale=1.0, sample_shape=[self.M, self.K])\n",
    "        x = Normal(loc=tf.matmul(w, z, transpose_b=True),\n",
    "                   scale=stddv_datapoints*tf.ones([self.D, self.M]))\n",
    "\n",
    "        # INFERENCE\n",
    "        qw_variables = [tf.Variable(tf.random_normal([self.D, self.K])),\n",
    "                        tf.Variable(tf.random_normal([self.D, self.K]))]\n",
    "\n",
    "        qw = Normal(loc=qw_variables[0], scale=tf.nn.softplus(qw_variables[1]))\n",
    "\n",
    "        qz_variables = [tf.Variable(tf.random_normal([self.N, self.K])),\n",
    "                        tf.Variable(tf.random_normal([self.N, self.K]))]\n",
    "\n",
    "        qz = Normal(loc=tf.gather(qz_variables[0], idx_ph),\n",
    "                    scale=tf.nn.softplus(tf.gather(qz_variables[1], idx_ph)))\n",
    "\n",
    "        inference_w = ed.KLqp({w: qw}, data={x: x_ph, z: qz})\n",
    "        inference_z = ed.KLqp({z: qz}, data={x: x_ph, w: qw})\n",
    "\n",
    "        scale_factor = float(self.N) / self.M\n",
    "        inference_w.initialize(scale={x: scale_factor, z: scale_factor},\n",
    "                               var_list=qz_variables,\n",
    "                               n_samples=5, n_iter=2000)\n",
    "        inference_z.initialize(scale={x: scale_factor, z: scale_factor},\n",
    "                               var_list=qw_variables,\n",
    "                               n_samples=5)\n",
    "\n",
    "        sess = ed.get_session()\n",
    "        tf.global_variables_initializer().run()\n",
    "        loss = []\n",
    "        for _ in range(inference_w.n_iter):\n",
    "            x_batch, idx_batch = self.__next_batch(x_train)\n",
    "            for _ in range(5):\n",
    "                inference_z.update(feed_dict={x_ph: x_batch, \\\n",
    "                                              idx_ph: idx_batch})\n",
    "\n",
    "            info_dict = inference_w.update(feed_dict={x_ph: x_batch, \\\n",
    "                                                      idx_ph: idx_batch})\n",
    "            inference_w.print_progress(info_dict)\n",
    "\n",
    "            t = info_dict['t']\n",
    "            loss.append(info_dict['loss'])\n",
    "        pd.Series(loss).plot()\n",
    "        \n",
    "        w_post = Normal(loc=qw_variables[0], scale=tf.nn.softplus(qw_variables[1]))\n",
    "        z_post = Normal(loc=qz_variables[0],\n",
    "                    scale=tf.nn.softplus(qz_variables[1]))\n",
    "        x_post = Normal(loc=tf.matmul(w_post, z_post, transpose_b=True),\n",
    "                   scale=stddv_datapoints*tf.ones([self.D, self.N]))\n",
    "\n",
    "        \n",
    "        n_rep = 100 # number of replicated datasets we generate\n",
    "        holdout_gen = np.zeros((n_rep, x_train.shape[0], x_train.shape[1]))\n",
    "\n",
    "        for i in range(n_rep):\n",
    "            x_generated = x_post.sample().eval()\n",
    "\n",
    "            # look only at the heldout entries\n",
    "            holdout_gen[i] = np.multiply(x_generated, holdout_mask)\n",
    "\n",
    "        n_eval = 10 # we draw samples from the inferred Z and W\n",
    "        obs_ll = []\n",
    "        rep_ll = []\n",
    "        for j in range(n_eval):\n",
    "            w_sample = w_post.sample().eval()\n",
    "            z_sample = z_post.sample().eval()\n",
    "\n",
    "            holdoutmean_sample = np.multiply(w_sample.dot(z_sample.T), holdout_mask)\n",
    "            obs_ll.append(np.mean(stats.norm(holdoutmean_sample, \\\n",
    "                                stddv_datapoints).logpdf(x_vad), axis=0))\n",
    "\n",
    "            rep_ll.append(np.mean(stats.norm(holdoutmean_sample, \\\n",
    "                                stddv_datapoints).logpdf(holdout_gen),axis=1))\n",
    "\n",
    "        obs_ll_per_zi, rep_ll_per_zi = np.mean(np.array(obs_ll), axis=0), np.mean(np.array(rep_ll), axis=0)\n",
    "\n",
    "        pvals = np.array([np.mean(rep_ll_per_zi[:,i] < obs_ll_per_zi[i]) for i in range(len(obs_ll_per_zi))])\n",
    "        holdout_subjects = np.unique(holdout_col)\n",
    "        self.overall_pval = np.mean(pvals[holdout_subjects])\n",
    "        print(\"Predictive check p-values for K={}\".format(self.K), self.overall_pval)\n",
    "\n",
    "        #results\n",
    "        # Ahat and Zhat in the paper\n",
    "        self.x_post_np = x_post.mean().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "randseed = 1592223649\n",
    "random.seed(randseed)\n",
    "np.random.seed(randseed)\n",
    "tf.set_random_seed(randseed)\n",
    "\n",
    "\n",
    "Nsim = 500 #num of simulations\n",
    "N = 1000 #num of datapoints\n",
    "A = np.zeros((N, 2))\n",
    "\n",
    "C = np.random.normal(0,1, size = N)# confounder\n",
    "\n",
    "A[:,0] = 0.3*C + np.random.normal(0,1, size = N) # cause 1\n",
    "A[:,1] = 0.4*C + np.random.normal(0,1, size = N) # cause 2\n",
    "\n",
    "# scenario 1: no real cause\n",
    "true_coeffs1 = [0.0,0.0,0.5]\n",
    "Y1 = np.dot(A, true_coeffs1[:2]) + true_coeffs1[2]*C + np.random.normal(0,1, size = [Nsim, N])\n",
    "\n",
    "# scenario 2: one real cause\n",
    "true_coeffs2 = [0.0,0.3,0.5]\n",
    "Y2 = np.dot(A, true_coeffs2[:2]) + true_coeffs2[2]*C + np.random.normal(0,1, size = [Nsim, N])\n",
    "\n",
    "\n",
    "# standardize the data for PPCA\n",
    "for s in range(Nsim):\n",
    "    A = (A - A.mean(axis=0))/A.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [100%] ██████████████████████████████ Elapsed: 22s | Loss: 3227.481\n",
      "Predictive check p-values for K=1 0.4691185410334346\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "randseed = 1592223649\n",
    "random.seed(randseed)\n",
    "np.random.seed(randseed)\n",
    "tf.set_random_seed(randseed)\n",
    "\n",
    "stddv_datapoints = 1.0\n",
    "K=1\n",
    "\n",
    "\n",
    "ppca = PPCA(A.T, K, 100, 0.2)\n",
    "ppca.run()\n",
    "x_post_np = ppca.coef_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: no real cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle\n",
      "RMSE:  0.03370610636163551 Coeff:  [0.0021 0.0017] Std err:  [0.0015 0.0015] p-value:  [0.1552 0.2662]\n",
      "Unadjusted\n",
      "RMSE:  0.1564646258176551 Coeff:  [0.1252 0.1768] Std err:  [0.0014 0.0014] p-value:  [0. 0.]\n",
      "Med. Dcf\n",
      "RMSE:  0.1362654221936214 Coeff:  [0.1018 0.1447] Std err:  [0.0022 0.0026] p-value:  [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "# Oracle\n",
    "X_aug = np.column_stack([A, C])\n",
    "X = sm.add_constant(X_aug)\n",
    "coeffs = []\n",
    "for s in range(Nsim):\n",
    "    model = sm.OLS(Y1[s, :].T, X)\n",
    "    res = model.fit_regularized(L1_wt=0, maxiter=5000)\n",
    "    coeffs.append(res.params[1:3])\n",
    "    \n",
    "coeffs = np.array(coeffs)\n",
    "rmse = np.sqrt(np.mean((coeffs-0)**2))\n",
    "t2, p2 = stats.ttest_1samp(coeffs,0)\n",
    "print(\"Oracle\")\n",
    "print (\"RMSE: \", rmse, \"Coeff: \", coeffs.mean(axis=0), \"Std err: \", coeffs.std(axis=0)/np.sqrt(Nsim), \"p-value: \", p2)\n",
    "\n",
    "# Unadjusted\n",
    "X = sm.add_constant(A)\n",
    "coeffs = []\n",
    "for s in range(Nsim):\n",
    "    model = sm.OLS(Y1[s, :].T, X)\n",
    "    res = model.fit_regularized(L1_wt=0, maxiter=5000)\n",
    "    coeffs.append(res.params[1:3])\n",
    "    \n",
    "coeffs = np.array(coeffs)\n",
    "rmse = np.sqrt(np.mean((coeffs-0)**2))\n",
    "t2, p2 = stats.ttest_1samp(coeffs,0)\n",
    "print(\"Unadjusted\")\n",
    "print (\"RMSE: \", rmse, \"Coeff: \", coeffs.mean(axis=0), \"Std err: \", coeffs.std(axis=0)/np.sqrt(Nsim), \"p-value: \", p2)\n",
    "\n",
    "# Adjusted\n",
    "X_aug = np.column_stack([A, x_post_np.T])\n",
    "X = sm.add_constant(X_aug)\n",
    "coeffs = []\n",
    "for s in range(Nsim):\n",
    "    model = sm.OLS(Y1[s, :].T, X)\n",
    "    res = model.fit_regularized(L1_wt=0, maxiter=5000)\n",
    "    coeffs.append(res.params[1:3])\n",
    "    \n",
    "coeffs = np.array(coeffs)\n",
    "rmse = np.sqrt(np.mean((coeffs-0)**2))\n",
    "t2, p2 = stats.ttest_1samp(coeffs,0)\n",
    "print(\"Med. Dcf\")\n",
    "print (\"RMSE: \", rmse, \"Coeff: \", coeffs.mean(axis=0), \"Std err: \", coeffs.std(axis=0)/np.sqrt(Nsim), \"p-value: \", p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: one real cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle\n",
      "RMSE:  0.23297618249279053 Coeff:  [0.0019 0.3262] Std err:  [0.0015 0.0014] p-value:  [0.2051 0.    ]\n",
      "Unadjusted\n",
      "RMSE:  0.36761694477237106 Coeff:  [0.1258 0.5025] Std err:  [0.0014 0.0014] p-value:  [0. 0.]\n",
      "Med. Dcf\n",
      "RMSE:  0.34218470221437003 Coeff:  [0.1006 0.468 ] Std err:  [0.002  0.0024] p-value:  [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "# Oracle\n",
    "X_aug = np.column_stack([A, C])\n",
    "X = sm.add_constant(X_aug)\n",
    "coeffs = []\n",
    "for s in range(Nsim):\n",
    "    model = sm.OLS(Y2[s, :].T, X)\n",
    "    res = model.fit_regularized(L1_wt=0, maxiter=5000)\n",
    "    coeffs.append(res.params[1:3])\n",
    "    \n",
    "coeffs = np.array(coeffs)\n",
    "rmse = np.sqrt(np.mean((coeffs-0)**2))\n",
    "t2, p2 = stats.ttest_1samp(coeffs,0)\n",
    "print(\"Oracle\")\n",
    "print (\"RMSE: \", rmse, \"Coeff: \", coeffs.mean(axis=0), \"Std err: \", coeffs.std(axis=0)/np.sqrt(Nsim), \"p-value: \", p2)\n",
    "\n",
    "# Unadjusted\n",
    "X = sm.add_constant(A)\n",
    "coeffs = []\n",
    "for s in range(Nsim):\n",
    "    model = sm.OLS(Y2[s, :].T, X)\n",
    "    res = model.fit_regularized(L1_wt=0, maxiter=5000)\n",
    "    coeffs.append(res.params[1:3])\n",
    "    \n",
    "coeffs = np.array(coeffs)\n",
    "rmse = np.sqrt(np.mean((coeffs-0)**2))\n",
    "t2, p2 = stats.ttest_1samp(coeffs,0)\n",
    "print(\"Unadjusted\")\n",
    "print (\"RMSE: \", rmse, \"Coeff: \", coeffs.mean(axis=0), \"Std err: \", coeffs.std(axis=0)/np.sqrt(Nsim), \"p-value: \", p2)\n",
    "\n",
    "# Adjusted\n",
    "X_aug = np.column_stack([A, x_post_np.T])\n",
    "X = sm.add_constant(X_aug)\n",
    "coeffs = []\n",
    "for s in range(Nsim):\n",
    "    model = sm.OLS(Y2[s, :].T, X)\n",
    "    res = model.fit_regularized(L1_wt=0, maxiter=5000)\n",
    "    coeffs.append(res.params[1:3])\n",
    "    \n",
    "coeffs = np.array(coeffs)\n",
    "rmse = np.sqrt(np.mean((coeffs-0)**2))\n",
    "t2, p2 = stats.ttest_1samp(coeffs,0)\n",
    "print(\"Med. Dcf\")\n",
    "print (\"RMSE: \", rmse, \"Coeff: \", coeffs.mean(axis=0), \"Std err: \", coeffs.std(axis=0)/np.sqrt(Nsim), \"p-value: \", p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate multi-cause confounder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(randseed)\n",
    "np.random.seed(randseed)\n",
    "tf.set_random_seed(randseed)\n",
    "\n",
    "N=5000\n",
    "K=10\n",
    "D=50\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "# Simulate causes and confounders\n",
    "C = np.random.normal(0, 1, size = [N, K])\n",
    "lambd = np.random.normal(0, 0.5, size = [K, D])\n",
    "bernoulli_p = sigmoid(np.dot(C, lambd))                \n",
    "A = np.random.binomial(1, bernoulli_p, size = bernoulli_p.shape)\n",
    "\n",
    "# To ensure reproducibility we load the cause and confounder matrices saved previously\n",
    "A = np.loadtxt(DATA_PATH + 'simulated_causes.txt')\n",
    "C = np.loadtxt(DATA_PATH + 'simulated_multicause_conf.txt')\n",
    "\n",
    "# Simulate sets of coefficients and outcomes\n",
    "Nsim = 500\n",
    "betas = np.zeros((Nsim, D))\n",
    "gammas = np.zeros((Nsim, K))\n",
    "Ys = np.zeros((Nsim, N))\n",
    "for sim in range(Nsim):\n",
    "    beta = np.random.normal(0, 0.25, size = D)\n",
    "    zero_coeff_idx = np.random.choice(np.arange(len(beta)), size = 40, replace = False)\n",
    "    beta[zero_coeff_idx] = 0\n",
    "\n",
    "    gamma = np.random.normal(0, 0.25, size = K)\n",
    "    \n",
    "    noise = np.random.normal(0, 1, size = N).reshape(-1,1)\n",
    "    Y = np.dot(A, beta.reshape(D,1)) + np.dot(C, gamma.reshape(10,1)) + noise\n",
    "    \n",
    "    betas[sim,:] = beta\n",
    "    gammas[sim,:] = gamma\n",
    "    Ys[sim, np.newaxis] = Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(DATA_PATH + 'simulated_causes.txt', A)\n",
    "np.savetxt(DATA_PATH + 'simulated_multicause_conf.txt', C)\n",
    "np.savetxt(DATA_PATH + 'simulated_outcomes.txt', Ys)\n",
    "np.savetxt(DATA_PATH + 'simulated_true_coeffs.txt', betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the cause matrix\n",
    "X = A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMF deconfounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly holdout some entries of X\n",
    "num_datapoints, data_dim = X.shape\n",
    "\n",
    "holdout_portion = 0.5\n",
    "n_holdout = int(holdout_portion * num_datapoints * data_dim)\n",
    "\n",
    "holdout_row = np.random.randint(num_datapoints, size=n_holdout)\n",
    "holdout_col = np.random.randint(data_dim, size=n_holdout)\n",
    "holdout_mask = (sparse.coo_matrix((np.ones(n_holdout), \\\n",
    "                            (holdout_row, holdout_col)), \\\n",
    "                            shape = X.shape)).toarray()\n",
    "holdout_mask = np.minimum(holdout_mask, np.ones(X.shape))\n",
    "holdout_mask = np.float32(holdout_mask)\n",
    "\n",
    "\n",
    "holdout_subjects = np.unique(holdout_row)\n",
    "\n",
    "x_train = np.multiply(1-holdout_mask, X)\n",
    "x_vad = np.multiply(holdout_mask, X)\n",
    "\n",
    "M = 10  # minibatch size\n",
    "# for stochastic optimization\n",
    "# subsample datapoints\n",
    "def next_batch(x_train, M):\n",
    "    idx_batch = np.random.choice(N, M)\n",
    "    return x_train[idx_batch, :], idx_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/500 [ 99%] █████████████████████████████  ETA: 0sPredictive check p-values 0.496\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K_list = [450]\n",
    "K_pval = []\n",
    "for K in K_list:\n",
    "    train_data = np.array(x_train, dtype=int)\n",
    "    D = train_data.shape[1]\n",
    "    N = train_data.shape[0]\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    idx_ph = tf.placeholder(tf.int32, M)\n",
    "    x_ph = tf.placeholder(tf.float32, [M, D])\n",
    "\n",
    "    U = Gamma(0.1, 0.5, sample_shape=[M,K])\n",
    "    V = Gamma(0.1, 0.3, sample_shape=[D,K])\n",
    "    x = Poisson(tf.matmul(U, V, transpose_b=True))\n",
    "\n",
    "    min_scale = 1e-5\n",
    "\n",
    "    qV_variables = [tf.Variable(tf.random_uniform([D, K])), \\\n",
    "                    tf.Variable(tf.random_uniform([D, K]))]\n",
    "\n",
    "    qV = TransformedDistribution(\n",
    "                distribution=Normal(qV_variables[0],\\\n",
    "                                    tf.maximum(tf.nn.softplus(qV_variables[1]), \\\n",
    "                                               min_scale)),\n",
    "                bijector=tf.contrib.distributions.bijectors.Exp())\n",
    "\n",
    "\n",
    "    qU_variables = [tf.Variable(tf.random_uniform([N, K])), \\\n",
    "                    tf.Variable(tf.random_uniform([N, K]))]\n",
    "\n",
    "\n",
    "    qU = TransformedDistribution(\n",
    "                distribution=Normal(tf.gather(qU_variables[0], idx_ph),\\\n",
    "                                    tf.maximum(tf.nn.softplus(tf.gather(qU_variables[1], idx_ph)), \\\n",
    "                                               min_scale)),\n",
    "                bijector=tf.contrib.distributions.bijectors.Exp())\n",
    "\n",
    "\n",
    "    scale_factor = float(N) / M\n",
    "\n",
    "    # We apply variational EM with E-step over local variables\n",
    "    # and M-step to point estimate the global weight matrices.\n",
    "    inference_e = ed.KLqp({U: qU},\n",
    "                        data={x: x_ph, V:qV})\n",
    "    inference_m = ed.KLqp({V:qV},\n",
    "                       data={x: x_ph, U:qU})\n",
    "\n",
    "    optimizer_e = tf.train.RMSPropOptimizer(1e-4)\n",
    "    optimizer_m = tf.train.RMSPropOptimizer(1e-4)\n",
    "\n",
    "    inference_e.initialize(scale={x: scale_factor, U: scale_factor}, var_list=qU_variables, optimizer=\"rmsprop\")\n",
    "    inference_m.initialize(scale={x: scale_factor, U: scale_factor}, optimizer=\"rmsprop\")\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    loss = []\n",
    "    n_epoch = 20\n",
    "    n_iter_per_epoch = 500\n",
    "    for epoch in range(n_epoch):\n",
    "    #     print(\"Epoch {}\".format(epoch))\n",
    "        nll = 0.0\n",
    "\n",
    "        pbar = Progbar(n_iter_per_epoch)\n",
    "        for t in range(n_iter_per_epoch):\n",
    "            x_batch, idx_batch = next_batch(train_data, M)\n",
    "    #         x_batch = x_batch.todense()\n",
    "            pbar.update(t)\n",
    "            info_dict_e = inference_e.update(feed_dict={x_ph: x_batch, idx_ph: idx_batch})\n",
    "            info_dict_m = inference_m.update(feed_dict={x_ph: x_batch, idx_ph: idx_batch})\n",
    "            nll += info_dict_e['loss']\n",
    "    #         print('\\n'+str(info_dict_e['loss']))    \n",
    "            loss.append(info_dict_e['loss'])\n",
    "\n",
    "    pd.Series(loss).plot()\n",
    "\n",
    "    V_post = TransformedDistribution(\n",
    "                distribution=Normal(qV_variables[0],\\\n",
    "                                    tf.maximum(tf.nn.softplus(qV_variables[1]), \\\n",
    "                                               min_scale)),\n",
    "                bijector=tf.contrib.distributions.bijectors.Exp())\n",
    "    U_post = TransformedDistribution(\n",
    "                distribution=Normal(qU_variables[0],\\\n",
    "                                    tf.maximum(tf.nn.softplus(qU_variables[1]), \\\n",
    "                                               min_scale)),\n",
    "                bijector=tf.contrib.distributions.bijectors.Exp())\n",
    "\n",
    "    pmf_conf = U_post\n",
    "\n",
    "    x_post = Poisson(tf.matmul(U_post, V_post, transpose_b=True))\n",
    "\n",
    "    ### predictive check\n",
    "\n",
    "    n_rep = 100 # number of replicated datasets we generate\n",
    "    holdout_gen = np.zeros((n_rep, x_train.shape[0], x_train.shape[1]))\n",
    "    \n",
    "    for i in range(n_rep):\n",
    "        x_generated = x_post.sample().eval()\n",
    "\n",
    "        # look only at the heldout entries\n",
    "        holdout_gen[i] = np.multiply(x_generated, holdout_mask)\n",
    "\n",
    "    n_eval = 10 # we draw samples from the inferred Z and W\n",
    "    obs_ll = []\n",
    "    rep_ll = []\n",
    "    for j in range(n_eval):\n",
    "        U_sample = U_post.sample().eval()\n",
    "        V_sample = V_post.sample().eval()\n",
    "\n",
    "        holdoutmean_sample = np.multiply(U_sample.dot(V_sample.T), holdout_mask)\n",
    "        obs_ll.append(\\\n",
    "            np.mean(np.ma.masked_invalid(stats.poisson.logpmf(np.array(x_vad, dtype=int), \\\n",
    "                                                              holdoutmean_sample)), axis=0))\n",
    "\n",
    "        rep_ll.append(\\\n",
    "            np.mean(np.ma.masked_invalid(stats.poisson.logpmf(holdout_gen, \\\n",
    "                                                              holdoutmean_sample)), axis=1))\n",
    "\n",
    "    obs_ll_per_zi, rep_ll_per_zi = np.mean(np.array(obs_ll), axis=0), np.mean(np.array(rep_ll), axis=0)\n",
    "\n",
    "    pvals = np.array([np.mean(rep_ll_per_zi[:,i] < obs_ll_per_zi[i]) for i in range(len(obs_ll_per_zi))])\n",
    "    holdout_subjects = np.unique(holdout_col)\n",
    "    overall_pval = np.mean(pvals[holdout_subjects])\n",
    "    print(\"Predictive check p-values\", overall_pval)\n",
    "    K_pval.append(overall_pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save result\n",
    "x_post_np = x_post.mean().eval()\n",
    "pmf_Z_post_np = pmf_conf.eval()\n",
    "\n",
    "np.savetxt(DATA_PATH + \"x_post_np_PMF_k450.txt\", x_post_np) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconfounder: DEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 50\n",
      "Epoch 0\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 5s\n",
      "Negative log-likelihood <= 391532.458\n",
      "Perplexity <= 175.706\n",
      "Epoch 1\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 5s\n",
      "Negative log-likelihood <= 207840.734\n",
      "Perplexity <= 15.546\n",
      "Epoch 2\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 5s\n",
      "Negative log-likelihood <= 185318.102\n",
      "Perplexity <= 11.548\n",
      "Epoch 3\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 6s\n",
      "Negative log-likelihood <= 181456.758\n",
      "Perplexity <= 10.974\n",
      "Epoch 4\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 180486.477\n",
      "Perplexity <= 10.834\n",
      "Epoch 5\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 5s\n",
      "Negative log-likelihood <= 179707.286\n",
      "Perplexity <= 10.723\n",
      "Epoch 6\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 179957.161\n",
      "Perplexity <= 10.759\n",
      "Epoch 7\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 5s\n",
      "Negative log-likelihood <= 179873.423\n",
      "Perplexity <= 10.747\n",
      "Epoch 8\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 6s\n",
      "Negative log-likelihood <= 179360.266\n",
      "Perplexity <= 10.674\n",
      "Epoch 9\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 179872.561\n",
      "Perplexity <= 10.747\n",
      "Epoch 10\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 179643.783\n",
      "Perplexity <= 10.714\n",
      "Epoch 11\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 179457.401\n",
      "Perplexity <= 10.688\n",
      "Epoch 12\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 179948.236\n",
      "Perplexity <= 10.757\n",
      "Epoch 13\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 179882.378\n",
      "Perplexity <= 10.748\n",
      "Epoch 14\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 180013.716\n",
      "Perplexity <= 10.767\n",
      "Epoch 15\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 179652.742\n",
      "Perplexity <= 10.715\n",
      "Epoch 16\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 179630.224\n",
      "Perplexity <= 10.712\n",
      "Epoch 17\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 4s\n",
      "Negative log-likelihood <= 179576.899\n",
      "Perplexity <= 10.705\n",
      "Epoch 18\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 3s\n",
      "Negative log-likelihood <= 179708.980\n",
      "Perplexity <= 10.723\n",
      "Epoch 19\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 5s\n",
      "Negative log-likelihood <= 179559.157\n",
      "Perplexity <= 10.702\n"
     ]
    }
   ],
   "source": [
    "N = x_train.shape[0]  # number of data points\n",
    "D = x_train.shape[1]  # data dimensionality\n",
    "min_scale = 1e-5\n",
    "print (N, D)\n",
    "train_data = np.array(x_train, dtype=int)\n",
    "\n",
    "\n",
    "\n",
    "q = 'lognormal'  # choice of q; 'lognormal' or 'gamma'\n",
    "shape = 0.1  # gamma shape parameter\n",
    "lr = 1e-3  # learning rate step-size\n",
    "logdir = '~/log/def/'\n",
    "logdir = os.path.expanduser(logdir)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# note this x matrix is transpose of the other matrices in PPCA/PMF\n",
    "x_ph = tf.placeholder(tf.float32, [M, D])\n",
    "idx_ph = tf.placeholder(tf.int32, M)\n",
    "\n",
    "\n",
    "# MODEL\n",
    "Ks = [2, 2]  #\n",
    "W1 = Gamma(0.1, 0.3, sample_shape=[Ks[1], Ks[0]])\n",
    "W0 = Gamma(0.1, 0.3, sample_shape=[Ks[0], D])\n",
    "\n",
    "z2 = Gamma(0.1, 0.1, sample_shape=[M, Ks[1]])\n",
    "z1 = Gamma(shape, shape / tf.matmul(z2, W1))\n",
    "\n",
    "x = Poisson(tf.matmul(z1, W0))\n",
    "\n",
    "\n",
    "# INFERENCE\n",
    "def pointmass_q(shape):\n",
    "    min_mean = 1e-3\n",
    "    mean_init = tf.random_normal(shape)\n",
    "    rv = PointMass(tf.maximum(tf.nn.softplus(tf.Variable(mean_init)), min_mean))\n",
    "    return rv\n",
    "\n",
    "\n",
    "def gamma_q(shape):\n",
    "    # Parameterize Gamma q's via shape and scale, with softplus unconstraints.\n",
    "    min_shape = 1e-3\n",
    "    min_scale = 1e-5\n",
    "    shape_init = 0.5 + 0.1 * tf.random_normal(shape)\n",
    "    scale_init = 0.1 * tf.random_normal(shape)\n",
    "    rv = Gamma(tf.maximum(tf.nn.softplus(tf.Variable(shape_init)),\n",
    "                        min_shape),\n",
    "             tf.maximum(1.0 / tf.nn.softplus(tf.Variable(scale_init)),\n",
    "                        1.0 / min_scale))\n",
    "    return rv\n",
    "\n",
    "\n",
    "def lognormal_q(shape):\n",
    "    min_scale = 1e-5\n",
    "    loc_init = tf.random_normal(shape)\n",
    "    scale_init = 0.1 * tf.random_normal(shape)\n",
    "    rv = TransformedDistribution(\n",
    "      distribution=Normal(\n",
    "          tf.Variable(loc_init),\n",
    "          tf.maximum(tf.nn.softplus(tf.Variable(scale_init)), min_scale)),\n",
    "      bijector=tf.contrib.distributions.bijectors.Exp())\n",
    "    return rv\n",
    "\n",
    "\n",
    "\n",
    "qW1 = pointmass_q(W1.shape)\n",
    "qW0 = pointmass_q(W0.shape)\n",
    "\n",
    "\n",
    "qz2 = lognormal_q(z2.shape)\n",
    "qz1 = lognormal_q(z1.shape)\n",
    "\n",
    "qz2_variables = [tf.Variable(tf.random_uniform([N, Ks[1]])), \\\n",
    "                tf.Variable(tf.random_uniform([N, Ks[1]]))]\n",
    "\n",
    "\n",
    "qz2 = TransformedDistribution(\n",
    "            distribution=Normal(tf.gather(qz2_variables[0], idx_ph),\\\n",
    "                                tf.maximum(tf.nn.softplus(tf.gather(qz2_variables[1], idx_ph)), \\\n",
    "                                           min_scale)),\n",
    "            bijector=tf.contrib.distributions.bijectors.Exp())\n",
    "\n",
    "# We apply variational EM with E-step over local variables\n",
    "# and M-step to point estimate the global weight matrices.\n",
    "inference_e = ed.KLqp({z1: qz1, z2: qz2},\n",
    "                      data={x: x_ph, W0: qW0, W1: qW1})\n",
    "inference_m = ed.MAP({W0: qW0, W1: qW1},\n",
    "                     data={x: x_ph, z1: qz1, z2: qz2})\n",
    "\n",
    "scale_factor = float(N) / M\n",
    "\n",
    "\n",
    "optimizer_e = tf.train.RMSPropOptimizer(lr)\n",
    "optimizer_m = tf.train.RMSPropOptimizer(lr)\n",
    "timestamp = datetime.strftime(datetime.utcnow(), \"%Y%m%d_%H%M%S\")\n",
    "logdir += timestamp + '_' + '_'.join([str(ks) for ks in Ks]) + \\\n",
    "    '_q_' + str(q) + '_lr_' + str(lr)\n",
    "kwargs = {'optimizer': optimizer_e,\n",
    "          'n_print': 100,\n",
    "          'logdir': logdir,\n",
    "          'log_timestamp': False, \n",
    "          'scale': {x: scale_factor, z2: scale_factor}}\n",
    "\n",
    "if q == 'gamma':\n",
    "    kwargs['n_samples'] = 30\n",
    "inference_e.initialize(**kwargs)\n",
    "inference_m.initialize(optimizer=optimizer_m, \\\n",
    "                       scale = {x: scale_factor, z2: scale_factor})\n",
    "\n",
    "sess = ed.get_session()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "loss = []\n",
    "n_epoch = 20\n",
    "n_iter_per_epoch = 1000\n",
    "for epoch in range(n_epoch):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    nll = 0.0\n",
    "\n",
    "    pbar = Progbar(n_iter_per_epoch)\n",
    "    for t in range(1, n_iter_per_epoch + 1):\n",
    "        x_batch, idx_batch = next_batch(train_data, M)\n",
    "        # this extra step is because the x matrix is \n",
    "        # transpose of the other matrices in PPCA/PMF\n",
    "#         x_batch = x_batch.T \n",
    "        pbar.update(t)\n",
    "        info_dict_e = inference_e.update(feed_dict={x_ph: x_batch, idx_ph: idx_batch})\n",
    "        info_dict_m = inference_m.update(feed_dict={x_ph: x_batch, idx_ph: idx_batch})\n",
    "        nll += info_dict_e['loss']\n",
    "        loss.append(info_dict_e['loss'])\n",
    "\n",
    "    # Compute perplexity averaged over a number of training iterations.\n",
    "    # The model's negative log-likelihood of data is upper bounded by\n",
    "    # the variational objective.\n",
    "    nll = nll / n_iter_per_epoch\n",
    "    perplexity = np.exp(nll / np.sum(x_train))\n",
    "    print(\"Negative log-likelihood <= {:0.3f}\".format(nll))\n",
    "    print(\"Perplexity <= {:0.3f}\".format(perplexity))\n",
    "\n",
    "z2_post = TransformedDistribution(\n",
    "            distribution=Normal(qz2_variables[0],\\\n",
    "                                tf.maximum(tf.nn.softplus(qz2_variables[1]), \\\n",
    "                                           min_scale)),\n",
    "            bijector=tf.contrib.distributions.bijectors.Exp())\n",
    "\n",
    "z1_post = Gamma(shape, shape / tf.matmul(z2_post, qW1))\n",
    "\n",
    "x_post = Poisson(tf.matmul(z1_post, qW0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [100%] ██████████████████████████████ Elapsed: 27s\n",
      "Predictive check p-values 0.614\n"
     ]
    }
   ],
   "source": [
    "n_rep = 100 # number of replicated datasets we generate\n",
    "holdout_gen = np.zeros((n_rep, x_train.shape[0], x_train.shape[1]))\n",
    "\n",
    "for i in range(n_rep):\n",
    "    x_generated = x_post.sample().eval()\n",
    "    \n",
    "    # look only at the heldout entries\n",
    "    holdout_gen[i] = np.multiply(x_generated, holdout_mask)\n",
    "\n",
    "n_eval = 10 # we draw samples from the inferred Z and W\n",
    "obs_ll = []\n",
    "rep_ll = []\n",
    "pbar = Progbar(n_eval)\n",
    "for j in range(1, n_eval+1):\n",
    "    z1_sample = z1_post.sample().eval()\n",
    "    W0_sample = qW0.sample().eval()\n",
    "    \n",
    "    holdoutmean_sample = np.multiply(z1_sample.dot(W0_sample), holdout_mask)\n",
    "    obs_ll.append(np.mean(np.ma.masked_invalid(stats.poisson.logpmf(np.array(x_vad, dtype=int), holdoutmean_sample)), axis=0))\n",
    "\n",
    "    rep_ll.append(np.mean(np.ma.masked_invalid(stats.poisson.logpmf(holdout_gen, holdoutmean_sample)), axis=1))\n",
    "    pbar.update(j)\n",
    "    \n",
    "obs_ll_per_zi, rep_ll_per_zi = np.mean(np.array(obs_ll), axis=0), np.mean(np.array(rep_ll), axis=0)\n",
    "\n",
    "pvals = np.array([np.mean(rep_ll_per_zi[:,i] < obs_ll_per_zi[i]) for i in range(len(obs_ll_per_zi))])\n",
    "holdout_subjects = np.unique(holdout_col)\n",
    "overall_pval = np.mean(pvals[holdout_subjects])\n",
    "print(\"Predictive check p-values\", overall_pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct causes\n",
    "x_post_np = x_post.mean().eval()\n",
    "# drug latent variables\n",
    "def_Z_post_np = qW0.mean().eval()\n",
    "# patient latent variables\n",
    "z1_post_np = z1_post.mean().eval()\n",
    "### save result\n",
    "np.savetxt(DATA_PATH + \"x_post_np_DEF_2_2.txt\", x_post_np) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome model in R..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "rA4jMmMtfrJO",
    "UKH2LeJV6acn",
    "IZkxOn3tVoFd",
    "cG1609cc5G2-",
    "cnGaFw3TXOu4",
    "yK0rGVb9VcJK",
    "-yzXXuyCp8a0",
    "QCLRjpzf1bts"
   ],
   "default_view": {},
   "name": "latent_confounder_gene_testing.ipynb",
   "provenance": [
    {
     "file_id": "1THbZHTVUamCuyONzyWHtREtZcn163G9p",
     "timestamp": 1517254346174
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
